---
layout: mypost
title: 04-Kafka & ZMQ: 自动化交易流水线
categories: [Python, 消息队列, Kafka, ZeroMQ, Socket]
---

## 中间件

- 逻辑关系图

![middleware.png](/py_core/assets/04-practice/04/middleware.png)

### 消息队列

- 概念
  - 一个临时存放消息的容器，往该容器中推送消息；同时会监测容器变化，发送新消息，就取走数据

- 常见的消息队列
  - RabbitMQ
  - Kafka
  - RocketMQ
  - ZeroMQ

- 特点
  - 先进先出（FIFO），进去1，2，3；出来也是1，2，3
  - 栈是先进后出 进去1，2；出来是3，2，1
  - 生产者/消费者
  - 发布/订阅

- 应用场景
  - 异步处理
  - 服务解耦
  - 流量控制

- 如何确保消息不会丢失？
  - 生产消息-当生产者向broker写入消息，需要处理broker的响应，不论是同步还是异步发送消息，回调都需要做好异常处理，在异常代码中重试，当多次发送失败需要作报警/日志记录。
  - broker存储消息-消息存储阶段需要在消息刷新磁盘之后再给生产者响应，假设消息写入缓存中就返回响应，如果机器断电消息就丢失了，而生产者会误以为发送成功。如果broker是集群部署，有多副本机制，即消息不仅仅要写入当前 Broker ,还需要写入副本机中
  - 消费消息-消费端从broker拉取消息，只要消费端在收到消息后，不立即发送消费ack确认给broker，而是等执行完业务逻辑后，在发送消费ack确认，也可以保证消息不丢失
  - 首先是将消息推送到 Broker 时我们要保证消息的确是到了 Broker 。然后就是存在 Broker 中的消息要保证持久化，这样能解决 Broker 重启导致的内存中的消息不会被丢失。最后就是消费者在消费消息时，我们通过手动 ack 来告诉 Broker 是不是应该将消息移除队列。

- 如何处理重复消息？
  - 为什么会出现重复消息？
    - 1.发送消息到broker，发送成功需要等待broker响应成功给到生产者，但可能存在broker已经写入了，由于网络原因，生产者没有收到broker的响应，然后生产者又重复生产力一次
    - 2.消费者拿到消息消费了，业务逻辑也走完了，事务提交了，此时需要更新 Consumer offset 了，然后这个消费者挂了，另一个消费者顶上，此时 Consumer offset 还没更新，于是又拿到刚才那条消息，业务又被执行了一遍。于是消息又重复了。
  - 幂等一致性
    - 同样的参数多次调用同一个接口和调用一次产生的结果都是一致的
  - 想要解决消息丢失和消息重复消费，前提条件是-全局唯一ID生成
    - 数据库自增主键
    - UUID
    - 雪花算法

- 如何处理消息积压？
  - 处理高并发场景下的消费能力问题
  - 生产者的生产速度和消费者的消费速度不匹配
    - 消息消费失败，反复重试
    - 消费能力弱，速度慢
  - 硬件临时扩容，提高消费能力，与此同时，降级一些非核心的业务，通过扩容和降级承担流量。如k8s的HPA
  - 排查解决异常问题，通过监控/日志等手段分析是否是消费端的代码有问题，优化代码
  - 如果是消费端的处理能力不足，可以通过水平扩容来提供消费端的并发处理能力。 注意在kafka中在扩容消费者的实例数的同时，必须同步扩容主题 Topic 的分区数量，确保消费者的实例数和分区数相等。如果消费者的实例数超过了分区数，由于分区是单线程消费，所以这样的扩容就没有效果。

### 发布订阅

![pub-sub.png](/py_core/assets/04-practice/04/pub-sub.png)

- 消息队列的模式是发布和订阅，一个或多个消息发布者可以发布消息，一个或多个消息接受者可以订阅消息。 从图中你可以看到，消息发布者和消息接受者之间没有直接耦合，其中，
  - 消息发布者将消息发送到分布式消息队列后，就结束了对消息的处理；
  - 消息接受者从分布式消息队列获取该消息后，即可进行后续处理，并不需要探寻这个消息从何而来。
  - 至于新增业务的问题，只要你对这类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，所以也就实现了业务的可扩展性设计。

- ZeroMQ是一个轻量级的消息队列，有三种使用模式
  - Request-Reply （和http类似 c/s结构）
  - Publish-Subscribe
  - Parallel Pipeline

- Publish-Subscribe模式

> 发布者

```python
import zmq
import time


def run():
    contect = zmq.Context()
    socket = contect.socket(zmq.PUB)
    socket.bind('tcp://*:6666')

    count = 1

    while True:
        time.sleep(1)
        dic = {
            "name": "tomtao626",
            "age": 18
        }
        socket.send_json(dic)
        print(dic)
        count += 1


if __name__ == '__main__':
    run()
```

> 订阅者

```python
import zmq


def run():
    context =  zmq.Context()
    socket = context.socket(zmq.SUB)
    socket.connect("tcp://127.0.0.1:6666")
    socket.setsockopt_string(zmq.SUBSCRIBE, '')

    print("client 1")
    while True:
        msg = socket.recv_json()
        print(msg)


if __name__ == '__main__':
    run()
```

- 如果有多个发布者，ZMQ 应该怎么做呢？
  - 多个发布者的话，不同的发布者使用不同的端口，而后订阅者根据匹配的端口读取消息

## 基于消息队列的 Orderbook 数据流

![zmq-kafka-orderbook.png](/py_core/assets/04-practice/04/zmq-kafka-orderbook.png)

